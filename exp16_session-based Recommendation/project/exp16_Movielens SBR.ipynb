{"cells":[{"cell_type":"markdown","metadata":{"id":"Ja63THdP5sjS"},"source":["# exp16. Movielens 영화 SBR"]},{"cell_type":"markdown","metadata":{"id":"iFMDa-na5sjW"},"source":["## 0. 들어가며\n","\n","이번에 우리는 `Movielens 1M Dataset`을 기반으로, Session based Recommendation 시스템을 제작해 보겠습니다.\n","\n","우선 주요 라이브러리 버전을 확인해 보죠."]},{"cell_type":"markdown","metadata":{"id":"tVxHLKaJ5sjX"},"source":["### 0.1 Loading"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":489,"status":"ok","timestamp":1647420586441,"user":{"displayName":"장병용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06434954116901156009"},"user_tz":-540},"id":"204mKTkv5sjX","outputId":"5e53e1b6-dcc1-4637-bcae-ec0e1dca2dc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.3.5\n","2.8.0\n"]}],"source":["import pandas as pd\n","import tensorflow as tf\n","import datetime as dt\n","from pathlib import Path\n","\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(pd.__version__)\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0gWpFbH6yOB"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"R5imU9sT5sja"},"source":["```\n","1) 데이터 확인\n","$ ls -l ~/data\n","\n","2) 프로젝트 폴더 생성\n","$ mkdir -p ~/aiffel/yoochoose\n","\n","3) 프로젝트 폴더로 데이터 폴더 링크 연결\n","$ ln -s ~/data/* ~/aiffel/yoochoose/data\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0xyjcla5sja"},"outputs":[],"source":["data_path = Path('/content/drive/Othercomputers/내 컴퓨터 (1)/project/aiffel_exp/data/exp16') \n","train_path = data_path / 'ratings.dat'\n","\n","def load_data(data_path: Path, nrows=None):\n","    data = pd.read_csv(data_path, sep='::', header=None, usecols=[0, 1, 2, 3], dtype={0: np.int32, 1: np.int32, 2: np.int32}, nrows=nrows)\n","    data.columns = ['UserId', 'ItemId', 'Rating', 'Time']\n","    return data\n","\n","data = load_data(train_path, None)\n","data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ETGGs4RY6Yzt"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"o9HaGTw-5sjb"},"source":["* 여기서 이전 실습 내역과 가장 크게 다른 부분은 바로 세션ID 대신 UserID 항목이 들어갔다는 점입니다. 이 데이터셋은 명확한 1회 세션의 세션ID를 포함하지 않고 있습니다. 그래서 이번에는 UserID가 세션ID 역할을 해야 합니다.\n","\n","* Rating 정보가 포함되어 있습니다. 이전 실습 내역에서는 이런 항목이 포함되어 있지 않았으므로, 무시하고 제외할 수 있습니다. 하지만, 직전에 봤던 영화가 맘에 들었는지가 비슷한 영화를 더 고르게 하는 것과 상관이 있을 수도 있습니다. 아울러, Rating이 낮은 데이터를 어떻게 처리할지도 고민해야 합니다.\n","\n","* Time 항목에는 UTC time 가 포함되어, 1970년 1월 1일부터 경과된 초 단위 시간이 기재되어 있습니다.\n","\n","위와 같은 정보를 바탕으로 오늘의 실습과정과 유사한 프로젝트 과정을 진행해 보겠습니다."]},{"cell_type":"markdown","metadata":{"id":"YA_stPsz5sjc"},"source":["## 1. 데이터의 전처리\n","***\n","위와 같이 간단히 구성해 본 데이터셋을 꼼꼼히 살펴보면서 항목별 기본 분석, session length, session time, cleaning 등의 작업을 진행합니다.\n","특히, 이 데이터셋에서는 Session이 아닌 UserID 단위로 데이터가 생성되어 있으므로, 이를 Session 단위로 어떻게 해석할지에 주의합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yUturDg05sjd"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-11-e1b73cc548a3\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 데이터 설명(README)를 읽어 봅니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:/project/aiffel_exp/data/exp16/README'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/project/aiffel_exp/data/exp16/README'"]}],"source":["# 데이터 설명(README)를 읽어 봅니다. \n","import os\n","f = open('D:/project/aiffel_exp/data/exp16/README', 'r')\n","while True:\n","    line = f.readline()\n","    if not line: break\n","    print(line)\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"OLLVoetK5sjd"},"source":["UserID::MovieID::Rating::Timestamp\n","\n","- UserIDs range between 1 and 6040 \n","- MovieIDs range between 1 and 3952\n","- Ratings are made on a 5-star scale (whole-star ratings only)\n","- Timestamp is represented in seconds since the epoch as returned by time(2)\n","- Each user has at least 20 ratings\n","\n","UserID::Gender::Age::Occupation::Zip-code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZVk0kAKm5sje"},"outputs":[],"source":["data['UserId'].nunique(), data['ItemId'].nunique()"]},{"cell_type":"markdown","metadata":{"id":"DrFMuO_G5sje"},"source":["### 1.2 Session Length\n","***\n","각 세션이 대략 몇 개의 클릭 데이터를 갖는지도 살펴보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6JLIHO8f5sjf"},"outputs":[],"source":["session_length = data.groupby('UserId').size()\n","session_length"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UfXAX6_k5sjf"},"outputs":[],"source":["session_length.median(), session_length.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jXyNO3aq5sjf"},"outputs":[],"source":["session_length.min(), session_length.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rQF0iqi35sjf"},"outputs":[],"source":["session_length.quantile(0.999)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wpEmVu0L5sjg"},"outputs":[],"source":["long_session = session_length[session_length==200].index[0]\n","data[data['UserId']==long_session]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wueREOES5sjg"},"outputs":[],"source":["length_count = session_length.groupby(session_length).size()\n","length_percent_cumsum = length_count.cumsum() / length_count.sum()\n","length_percent_cumsum_999 = length_percent_cumsum[length_percent_cumsum \u003c 0.999]\n","\n","length_percent_cumsum_999"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MfMQxZW05sjh"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12, 10))\n","plt.bar(x=length_percent_cumsum_999.index,\n","        height=length_percent_cumsum_999, color='red')\n","plt.xticks(length_percent_cumsum_999.index)\n","plt.yticks(np.arange(0, 1.01, 0.05))\n","plt.title('Cumsum Percentage Until 0.999', size=20)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"0oWNf8yd5sjh"},"source":["### 1.3 Session Time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"U3uR2Y3I5sji"},"outputs":[],"source":["oldest, latest = data['Time'].min(), data['Time'].max()\n","print(oldest) \n","print(latest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"spRwUuPa5sji"},"outputs":[],"source":["type(latest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ilwTxEii5sji"},"outputs":[],"source":["month_ago = latest - dt.timedelta(30)     # 최종 날짜로부터 30일 이전 날짜를 구한다.  \n","data = data[data['Time'] \u003e month_ago]   # 방금 구한 날짜 이후의 데이터만 모은다. \n","data"]},{"cell_type":"markdown","metadata":{"id":"8NX3BYFL5sjj"},"source":["### 1.3 Data Cleansin"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fVcukd0t5sjj"},"outputs":[],"source":["# short_session을 제거한 다음 unpopular item을 제거하면 다시 길이가 1인 session이 생길 수 있습니다.\n","# 이를 위해 반복문을 통해 지속적으로 제거 합니다.\n","def cleanse_recursive(data: pd.DataFrame, shortest, least_click) -\u003e pd.DataFrame:\n","    while True:\n","        before_len = len(data)\n","        data = cleanse_short_session(data, shortest)\n","        data = cleanse_unpopular_item(data, least_click)\n","        after_len = len(data)\n","        if before_len == after_len:\n","            break\n","    return data\n","\n","\n","def cleanse_short_session(data: pd.DataFrame, shortest):\n","    session_len = data.groupby('SessionId').size()\n","    session_use = session_len[session_len \u003e= shortest].index\n","    data = data[data['SessionId'].isin(session_use)]\n","    return data\n","\n","\n","def cleanse_unpopular_item(data: pd.DataFrame, least_click):\n","    item_popular = data.groupby('ItemId').size()\n","    item_use = item_popular[item_popular \u003e= least_click].index\n","    data = data[data['ItemId'].isin(item_use)]\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Iw3Sh8n35sjj"},"outputs":[],"source":["data = cleanse_recursive(data, shortest=2, least_click=5)\n","data"]},{"cell_type":"markdown","metadata":{"id":"Dx2uYmUD5sjj"},"source":["### 1.4 train / valid / test split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9tIq3MdC5sjj"},"outputs":[],"source":["test_path = data_path / 'yoochoose-test.dat'\n","test= load_data(test_path)\n","test['Time'].min(), test['Time'].max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"R62htP365sjj"},"outputs":[],"source":["def split_by_date(data: pd.DataFrame, n_days: int):\n","    final_time = data['Time'].max()\n","    session_last_time = data.groupby('SessionId')['Time'].max()\n","    session_in_train = session_last_time[session_last_time \u003c final_time - dt.timedelta(n_days)].index\n","    session_in_test = session_last_time[session_last_time \u003e= final_time - dt.timedelta(n_days)].index\n","\n","    before_date = data[data['SessionId'].isin(session_in_train)]\n","    after_date = data[data['SessionId'].isin(session_in_test)]\n","    after_date = after_date[after_date['ItemId'].isin(before_date['ItemId'])]\n","    return before_date, after_date"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hFvATGpD5sjk"},"outputs":[],"source":["tr, test = split_by_date(data, n_days=1)\n","tr, val = split_by_date(tr, n_days=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6t71XYo75sjk"},"outputs":[],"source":["# data에 대한 정보를 살펴봅니다.\n","def stats_info(data: pd.DataFrame, status: str):\n","    print(f'* {status} Set Stats Info\\n'\n","          f'\\t Events: {len(data)}\\n'\n","          f'\\t Sessions: {data[\"SessionId\"].nunique()}\\n'\n","          f'\\t Items: {data[\"ItemId\"].nunique()}\\n'\n","          f'\\t First Time : {data[\"Time\"].min()}\\n'\n","          f'\\t Last Time : {data[\"Time\"].max()}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wq0wP_GZ5sjk"},"outputs":[],"source":["stats_info(tr, 'train')\n","stats_info(val, 'valid')\n","stats_info(test, 'test')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"G9FfOWQD5sjk"},"outputs":[],"source":["# train set에 없는 아이템이 val, test기간에 생길 수 있으므로 train data를 기준으로 인덱싱합니다.\n","id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n","\n","def indexing(df, id2idx):\n","    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))  # id2idx에 없는 아이템은 모르는 값(-1) 처리 해줍니다.\n","    return df\n","\n","tr = indexing(tr, id2idx)\n","val = indexing(val, id2idx)\n","test = indexing(test, id2idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eVppFvHY5sjk"},"outputs":[],"source":["save_path = data_path / 'processed'\n","save_path.mkdir(parents=True, exist_ok=True)\n","\n","tr.to_pickle(save_path / 'train.pkl')\n","val.to_pickle(save_path / 'valid.pkl')\n","test.to_pickle(save_path / 'test.pkl')"]},{"cell_type":"markdown","metadata":{"id":"eFpXEEeq5sjk"},"source":["##  2. 미니 배치의 구성\n","실습 코드 내역을 참고하여 데이터셋과 미니 배치를 구성해 봅시다. Session-Parallel Mini-Batch의 개념에 따라, 학습 속도의 저하가 최소화될 수 있도록 구성합니다.\n","단, 위 Step 1에서 Session 단위를 어떻게 정의했느냐에 따라서 Session-Parallel Mini-Batch이 굳이 필요하지 않을 수도 있습니다."]},{"cell_type":"markdown","metadata":{"id":"W38xLp995sjl"},"source":["### 2.1 SessionDataset\n","데이터가 주어지면 세션이 시작되는 인덱스를 담는 값과 세션을 새로 인덱싱한 값을 갖는 클래스를 만듭니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EEXXVUxt5sjl"},"outputs":[],"source":["class SessionDataset:\n","    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n","\n","    def __init__(self, data):\n","        self.df = data\n","        self.click_offsets = self.get_click_offsets()\n","        self.session_idx = np.arange(self.df['SessionId'].nunique())  # indexing to SessionId\n","\n","    def get_click_offsets(self):\n","        \"\"\"\n","        Return the indexes of the first click of each session IDs,\n","        \"\"\"\n","        offsets = np.zeros(self.df['SessionId'].nunique() + 1, dtype=np.int32)\n","        offsets[1:] = self.df.groupby('SessionId').size().cumsum()\n","        return offsets"]},{"cell_type":"markdown","metadata":{"id":"sAdTsosC5sjl"},"source":["train데이터로 `SessionDataset` 객체를 만들고 인스턴스 변수들을 살펴보겠습니다.\n","`click_offsets` 변수는 각 세션이 시작된 인덱스를 담고 있습니다.\n","`session_idx` 변수는 각 세션을 인덱싱한 `np.array` 입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"W9WqHbZ35sjl"},"outputs":[],"source":["tr_dataset = SessionDataset(tr)\n","tr_dataset.df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"J4t9fENm5sjl"},"outputs":[],"source":["tr_dataset.click_offsets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S2Gg6lOX5sjl"},"outputs":[],"source":["tr_dataset.session_idx"]},{"cell_type":"markdown","metadata":{"id":"FxDrOhbw5sjm"},"source":["### 2.2 SessionDataLoader\n","파이썬 문법 중 iterator, generator에 대한 좀 더 친절한 안내가 필요하신 분은 이 자료(https://dojang.io/mod/page/view.php?id=2405)를 먼저 보시길 권장합니다.\n","\n","`SessionDataset` 객체를 받아서 Session-Parallel mini-batch를 만드는 클래스를 만듭니다.\n","`__iter__` 메서드는 모델 인풋, 라벨, 세션이 끝나는 곳의 위치를 `yield`합니다.\n","mask는 후에 RNN Cell State를 초기화하는데 사용할 것입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VRiVNLn25sjm"},"outputs":[],"source":["class SessionDataLoader:\n","    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n","\n","    def __init__(self, dataset: SessionDataset, batch_size=50):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","\n","    def __iter__(self):\n","        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n","        Yields:\n","            input (B,):  Item indices that will be encoded as one-hot vectors later.\n","            target (B,): a Variable that stores the target item indices\n","            masks: Numpy array indicating the positions of the sessions to be terminated\n","        \"\"\"\n","\n","        start, end, mask, last_session, finished = self.initialize()  # initialize 메소드에서 확인해주세요.\n","        \"\"\"\n","        start : Index Where Session Start\n","        end : Index Where Session End\n","        mask : indicator for the sessions to be terminated\n","        \"\"\"\n","\n","        while not finished:\n","            min_len = (end - start).min() - 1  # Shortest Length Among Sessions\n","            for i in range(min_len):\n","                # Build inputs \u0026 targets\n","                inp = self.dataset.df['item_idx'].values[start + i]\n","                target = self.dataset.df['item_idx'].values[start + i + 1]\n","                yield inp, target, mask\n","\n","            start, end, mask, last_session, finished = self.update_status(start, end, min_len, last_session, finished)\n","\n","    def initialize(self):\n","        first_iters = np.arange(self.batch_size)    # 첫 배치에 사용할 세션 Index를 가져옵니다.\n","        last_session = self.batch_size - 1    # 마지막으로 다루고 있는 세션 Index를 저장해둡니다.\n","        start = self.dataset.click_offsets[self.dataset.session_idx[first_iters]]       # data 상에서 session이 시작된 위치를 가져옵니다.\n","        end = self.dataset.click_offsets[self.dataset.session_idx[first_iters] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n","        mask = np.array([])   # session의 모든 아이템을 다 돌은 경우 mask에 추가해줄 것입니다.\n","        finished = False         # data를 전부 돌았는지 기록하기 위한 변수입니다.\n","        return start, end, mask, last_session, finished\n","\n","    def update_status(self, start: np.ndarray, end: np.ndarray, min_len: int, last_session: int, finished: bool):  \n","        # 다음 배치 데이터를 생성하기 위해 상태를 update합니다.\n","        \n","        start += min_len   # __iter__에서 min_len 만큼 for문을 돌았으므로 start를 min_len 만큼 더해줍니다.\n","        mask = np.arange(self.batch_size)[(end - start) == 1]  \n","        # end는 다음 세션이 시작되는 위치인데 start와 한 칸 차이난다는 것은 session이 끝났다는 뜻입니다. mask에 기록해줍니다.\n","\n","        for i, idx in enumerate(mask, start=1):  # mask에 추가된 세션 개수만큼 새로운 세션을 돌것입니다.\n","            new_session = last_session + i  \n","            if new_session \u003e self.dataset.session_idx[-1]:  # 만약 새로운 세션이 마지막 세션 index보다 크다면 모든 학습데이터를 돈 것입니다.\n","                finished = True\n","                break\n","            # update the next starting/ending point\n","            start[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session]]     # 종료된 세션 대신 새로운 세션의 시작점을 기록합니다.\n","            end[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session] + 1]\n","\n","        last_session += len(mask)  # 마지막 세션의 위치를 기록해둡니다.\n","        return start, end, mask, last_session, finished"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XPmdhUc65sjm"},"outputs":[],"source":["tr_data_loader = SessionDataLoader(tr_dataset, batch_size=4)\n","tr_dataset.df.head(15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Q9Tx1T4I5sjm"},"outputs":[],"source":["iter_ex = iter(tr_data_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZAoaILPm5sjm"},"outputs":[],"source":["inputs, labels, mask =  next(iter_ex)\n","print(f'Model Input Item Idx are : {inputs}')\n","print(f'Label Item Idx are : {\"\":5} {labels}')\n","print(f'Previous Masked Input Idx are {mask}')"]},{"cell_type":"markdown","metadata":{"id":"23FqXIok5sjn"},"source":["## 3. 모델 구성\n","이 부분도 실습 코드 내역을 참고하여 다양하게 모델 구조를 시도해 볼 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"MHzC4UtH5sjn"},"source":["### 3.1 Evaluation Metric\n","***\n","모델 성능 평가를 위한 지표를 보겠습니다.\n","모델 성능에 대한 지표로 precision이나 recall이 있습니다.\n","Session-Based Recommendation Task에서는 모델이 k개의 아이템을 제시했을 때, 유저가 클릭/ 구매한 n개의 아이템이 많아야 좋습니다.\n","이 때문에 recall의 개념을 확장한 `recall@k` 지표, precision의 개념을 확장한 `Mean Average Precision@k` 지표 등을 사용합니다.\n","추천에서는 몇 번째로 맞추느냐도 중요합니다. 구글에서 검색했을 때 1페이지에 원하는 결과가 나오지 않고 2페이지에 나온다면 유저 반응이 크게 떨어질 것입니다.\n","따라서 순서에 민감한 지표인 `MRR`, `NDCG` 같은 지표도 사용합니다.\n","이번 자료에서는 `MRR과` `Recall@k`를 사용하겠습니다. `MRR`은 정답 아이템이 나온 순번의 역수 값입니다.\n","따라서 정답 아이템이 추천 결과 앞쪽 순번에 나온다면 지표가 높아질 것이고 뒤쪽에 나오거나 안 나온다면 지표가 낮아질 것입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0EfLQGRg5sjn"},"outputs":[],"source":["def mrr_k(pred, truth: int, k: int):\n","    indexing = np.where(pred[:k] == truth)[0]\n","    if len(indexing) \u003e 0:\n","        return 1 / (indexing[0] + 1)\n","    else:\n","        return 0\n","\n","\n","def recall_k(pred, truth: int, k: int) -\u003e int:\n","    answer = truth in pred[:k]\n","    return int(answer)"]},{"cell_type":"markdown","metadata":{"id":"ZkTCwWoc5sjn"},"source":["### 3.2 Model Architecture\n","스텝 3에서 소개한 모델 구조를 구현하겠습니다. 모델 구조가 간단한 편이므로 Functional하게 모델을 만들겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GPQIeSi45sjn"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Dropout, GRU\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-yIGSXSp5sjn"},"outputs":[],"source":["def create_model(args):\n","    inputs = Input(batch_shape=(args.batch_size, 1, args.num_items))\n","    gru, _ = GRU(args.hsz, stateful=True, return_state=True, name='GRU')(inputs)\n","    dropout = Dropout(args.drop_rate)(gru)\n","    predictions = Dense(args.num_items, activation='softmax')(dropout)\n","    model = Model(inputs=inputs, outputs=[predictions])\n","    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n","    model.summary()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QVESa_4G5sjn"},"outputs":[],"source":["# 모델에 사용할 hyper-parameter를 class형식으로 관리하겠습니다.\n","class Args:\n","    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n","        self.tr = tr\n","        self.val = val\n","        self.test = test\n","        self.num_items = tr['ItemId'].nunique()\n","        self.num_sessions = tr['SessionId'].nunique()\n","        self.batch_size = batch_size\n","        self.hsz = hsz\n","        self.drop_rate = drop_rate\n","        self.lr = lr\n","        self.epochs = epochs\n","        self.k = k\n","\n","args = Args(tr, val, test, batch_size=2048, hsz=50, drop_rate=0.1, lr=0.001, epochs=3, k=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xUOQ7VGF5sjo"},"outputs":[],"source":["model = create_model(args)"]},{"cell_type":"markdown","metadata":{"id":"vNiQsoM25sjo"},"source":["## 4. 모델 학습\n","다양한 하이퍼파라미터를 변경해 보며 검증해 보도록 합니다. 실습 코드에 언급되었던 Recall, MRR 등의 개념들도 함께 관리될 수 있도록 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RWa78Cyf5sjo"},"outputs":[],"source":["# train 셋으로 학습하면서 valid 셋으로 검증합니다.\n","def train_model(model, args):\n","    train_dataset = SessionDataset(args.tr)\n","    train_loader = SessionDataLoader(train_dataset, batch_size=args.batch_size)\n","\n","    for epoch in range(1, args.epochs + 1):\n","        total_step = len(args.tr) - args.tr['SessionId'].nunique()\n","        tr_loader = tqdm(train_loader, total=total_step // args.batch_size, desc='Train', mininterval=1)\n","        for feat, target, mask in tr_loader:\n","            reset_hidden_states(model, mask)  # 종료된 session은 hidden_state를 초기화합니다. 아래 메서드에서 확인해주세요.\n","\n","            input_ohe = to_categorical(feat, num_classes=args.num_items)\n","            input_ohe = np.expand_dims(input_ohe, axis=1)\n","            target_ohe = to_categorical(target, num_classes=args.num_items)\n","\n","            result = model.train_on_batch(input_ohe, target_ohe)\n","            tr_loader.set_postfix(train_loss=result[0], accuracy = result[1])\n","\n","        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)  # valid set에 대해 검증합니다.\n","\n","        print(f\"\\t - Recall@{args.k} epoch {epoch}: {val_recall:3f}\")\n","        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:3f}\\n\")\n","\n","\n","def reset_hidden_states(model, mask):\n","    gru_layer = model.get_layer(name='GRU')  # model에서 gru layer를 가져옵니다.\n","    hidden_states = gru_layer.states[0].numpy()  # gru_layer의 parameter를 가져옵니다.\n","    for elt in mask:  # mask된 인덱스 즉, 종료된 세션의 인덱스를 돌면서\n","        hidden_states[elt, :] = 0  # parameter를 초기화 합니다.\n","    gru_layer.reset_states(states=hidden_states)\n","\n","\n","def get_metrics(data, model, args, k: int):  # valid셋과 test셋을 평가하는 코드입니다. \n","                                             # train과 거의 같지만 mrr, recall을 구하는 라인이 있습니다.\n","    dataset = SessionDataset(data)\n","    loader = SessionDataLoader(dataset, batch_size=args.batch_size)\n","    recall_list, mrr_list = [], []\n","\n","    total_step = len(data) - data['SessionId'].nunique()\n","    for inputs, label, mask in tqdm(loader, total=total_step // args.batch_size, desc='Evaluation', mininterval=1):\n","        reset_hidden_states(model, mask)\n","        input_ohe = to_categorical(inputs, num_classes=args.num_items)\n","        input_ohe = np.expand_dims(input_ohe, axis=1)\n","\n","        pred = model.predict(input_ohe, batch_size=args.batch_size)\n","        pred_arg = tf.argsort(pred, direction='DESCENDING')  # softmax 값이 큰 순서대로 sorting 합니다.\n","\n","        length = len(inputs)\n","        recall_list.extend([recall_k(pred_arg[i], label[i], k) for i in range(length)])\n","        mrr_list.extend([mrr_k(pred_arg[i], label[i], k) for i in range(length)])\n","\n","    recall, mrr = np.mean(recall_list), np.mean(mrr_list)\n","    return recall, mrr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nqK0MFd15sjo"},"outputs":[],"source":["# 학습 시간이 다소 오래 소요됩니다. 아래 주석을 풀지 마세요.\n","# train_model(model, args)\n","\n","# 학습된 모델을 불러옵니다.\n","model = tf.keras.models.load_model(data_path / 'trained_model')\n"]},{"cell_type":"markdown","metadata":{"id":"tk3m2-bt5sjo"},"source":["## 16.5 모델 테스트\n","미리 구성한 테스트셋을 바탕으로 Recall, MRR 을 확인해 봅니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n8QIyQ8A5sjo"},"outputs":[],"source":["def test_model(model, args, test):\n","    test_recall, test_mrr = get_metrics(test, model, args, 20)\n","    print(f\"\\t - Recall@{args.k}: {test_recall:3f}\")\n","    print(f\"\\t - MRR@{args.k}: {test_mrr:3f}\\n\")\n","\n","test_model(model, args, test)"]},{"cell_type":"markdown","metadata":{"id":"taLHboSb5sjp"},"source":[""]}],"metadata":{"colab":{"name":"exp16_Movielens SBR.ipynb","version":""},"interpreter":{"hash":"b917b148892ea97eb227a5873fd694967a649b57271cba3d0fbd658bbbf6409b"},"kernelspec":{"display_name":"Python 3.9.7 ('3.9')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}